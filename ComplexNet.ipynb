{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Complex Net\n",
    "blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train len 0\ntrain len 0\n"
     ]
    }
   ],
   "source": [
    "# A bit of setup\n",
    "from __future__ import print_function\n",
    "import os,sys,inspect\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from scipy import fft\n",
    "from torch import nn\n",
    "from resampy import resample\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from intervaltree import Interval, IntervalTree\n",
    "\n",
    "\n",
    "from music.resample import resample_musicnet\n",
    "from c2nn.utils import SignalDataset_music\n",
    "from c2nn.model import TransformerModel,TransformerGenerationModel\n",
    "from c2nn.train import train_transformer,train_model"
   ]
  },
  {
   "source": [
    "# Data process\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".. resampling music/musicnet.npz (44100Hz) into music/musicnet_11khz.npz (11000Hz)\n.. sampling with ratio 0.2494331065759637\n.. aggregating 1788 (0 / 330)\n"
     ]
    }
   ],
   "source": [
    "#resample\n",
    "resample_musicnet(\"music/musicnet.npz\", \"music/musicnet_11khz.npz\", 44100, 11000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_file, get .npy files\n",
    "\n",
    "fs = 11000            # samples/second\n",
    "window_size = 4096    # fourier window size\n",
    "d = 2048              # number of features\n",
    "m = 128               # (USED BY DCN) number of distinct notes\n",
    "stride = 512         # samples between windows\n",
    "stride_test = 128            # stride in test set\n",
    "k = 64            # number of window (time step) per piece\n",
    "k_test = 64\n",
    "data = np.load(open('music/musicnet_11khz.npz','rb'), encoding='latin1')\n",
    "\n",
    "test_data = ['2303','2382','1819']\n",
    "train_data = [f for f in data.files if f not in test_data]\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(train_data) 327\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-af08f54b26cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mXtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"music_train_x_64_{}.npy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"music_train_y_64_{}.npy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train data saved\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Miniconda3\\envs\\pt\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[1;32m--> 529\u001b[1;33m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    530\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Miniconda3\\envs\\pt\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "create train data set\n",
    "\"\"\"\n",
    "print(\"len(train_data)\",len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    print(i)\n",
    "    X,Y = data[train_data[i]]\n",
    "    for p in range(int((len(X)-window_size)/stride/k)):\n",
    "        Xtrain = np.empty([k,d,2])\n",
    "        Ytrain = np.zeros([k,m])\n",
    "        for j in range(k):\n",
    "            s = j*stride+p*k*stride# start from one second to give us some wiggle room for larger segments\n",
    "            X_fft = fft(X[s:s+window_size])\n",
    "            Xtrain[j, :, 0] = X_fft[0:d].real\n",
    "            Xtrain[j, :, 1] = X_fft[0:d].imag\n",
    "            # label stuff that's on in the center of the window\n",
    "            for label in Y[s+d/2]:\n",
    "                if (label.data[1]) >= m:\n",
    "                    continue\n",
    "                else:\n",
    "                    Ytrain[j,label.data[1]] = 1\n",
    "        Xtrain = Xtrain.reshape(k, d*2, order='F')\n",
    "        np.save(\"music/music_train_x_64_{}.npy\".format(index), Xtrain)\n",
    "        np.save(\"music/music_train_y_64_{}.npy\".format(index), Ytrain)\n",
    "        index = index + 1\n",
    "print(\"train data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f58e3e1fe580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mYtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mXtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"music_test_x_64_{}.npy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"music_test_y_64_{}.npy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "create the test set\n",
    "\"\"\"\n",
    "index = 0\n",
    "for i in range(len(test_data)):\n",
    "    print(i)\n",
    "    X,Y = data[test_data[i]]\n",
    "    for p in range(int((len(X)-window_size)/stride_test/k_test)):\n",
    "        Xtest = np.empty([k_test,d,2])\n",
    "        Ytest = np.zeros([k_test,m])\n",
    "        for j in range(k_test):\n",
    "            s = j*stride_test+p*k_test*stride_test\n",
    "            # start from one second to give us some wiggle room for larger segments\n",
    "            X_fft = fft(X[s:s+window_size])\n",
    "            Xtest[j, :, 0] = X_fft[0:d].real\n",
    "            Xtest[j, :, 1] = X_fft[0:d].imag           \n",
    "            # label stuff that's on in the center of the window\n",
    "            for label in Y[s+d/2]:\n",
    "                if (label.data[1]) >= m:\n",
    "                    continue\n",
    "                else:\n",
    "                    Ytest[j,label.data[1]] = 1\n",
    "        Xtest = Xtest.reshape(k_test, d*2, order='F')\n",
    "        np.save(\"music/music_test_x_64_{}.npy\".format(index), Xtest)\n",
    "        np.save(\"music/music_test_y_64_{}.npy\".format(index), Ytest)\n",
    "        index = index + 1\n",
    "print(\"finished\")"
   ]
  },
  {
   "source": [
    "# Train\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'seed': 1111,\n",
    "    'attn_dropout': 0.0, \n",
    "    'attn_mask' : False,\n",
    "    'batch_size' : 16,\n",
    "    'clip' : 0.35,\n",
    "    'data' : 'music',\n",
    "    'embed_dim' : 320,\n",
    "    'hidden_size' : 2048,\n",
    "    'lr' : 1e-4,\n",
    "    'modal_lengths' : [2048, 2048],\n",
    "    'model' : 'Transformer',\n",
    "    'nlevels' : 6,\n",
    "    'num_epochs' : 2000,\n",
    "    'num_heads' : 8,\n",
    "    'optim' : 'Adam',\n",
    "    'out_dropout' : 0.5,\n",
    "    'output_dim' : 128,\n",
    "    'path' : 'music/',\n",
    "    'relu_dropout' : 0.1,\n",
    "    'res_dropout' : 0.1,\n",
    "    'time_step' : 64\n",
    "}\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "torch.manual_seed(args['seed'])\n",
    "torch.cuda.manual_seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "random.seed(args['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Loading\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "print(\"Start loading the data....\")\n",
    "start_time = time.time() \n",
    "\n",
    "training_set = SignalDataset_music(args['path'], args['time_step'], train=True)\n",
    "test_set = SignalDataset_music(args['path'], args['time_step'], train=False)\n",
    "\n",
    "print(\"Finish loading the data....\")\n",
    "train_loader = torch.utils.data.DataLoader(training_set, batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "\"\"\"\n",
    "Train!!!\n",
    "\"\"\"\n",
    "train_transformer(args,training_set,train_loader,test_set,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "7"
          },
          {
           "key": 4,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}